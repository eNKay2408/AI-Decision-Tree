{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4c1a2e",
   "metadata": {},
   "source": [
    "# Dermatology Dataset Preparation\n",
    "\n",
    "In this section, we will:\n",
    "- Load and inspect the dataset\n",
    "- Perform missing value analysis and basic EDA\n",
    "- Impute missing values\n",
    "- Apply one-hot encoding to categorical features\n",
    "- Split the data into 16 subsets\n",
    "- Visualize the distribution of classes among subsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ec8fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. IMPORTS & SETTINGS\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# for consistent plots in notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003842de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. LOAD DERMATOLOGY DATASET\n",
    "# Column names from UCI description\n",
    "cols = [\n",
    "    'erythema', 'scaling', 'definite_borders', 'itching', 'koebner_phenomenon',\n",
    "    'polygonal_papules', 'follicular_papules', 'oral_mucosal_involvement',\n",
    "    'knee_and_elbow_involvement', 'scalp_involvement', 'family_history',\n",
    "    'melanin_incontinence', 'eosinophils_infiltrate', 'PNL_infiltrate',\n",
    "    'fibrosis_papillary_dermis', 'exocytosis', 'acanthosis', 'hyperkeratosis',\n",
    "    'parakeratosis', 'clubbing_rete_ridges', 'elongation_rete_ridges',\n",
    "    'thinning_suprapapillary_epidermis', 'spongiform_pustule',\n",
    "    'munro_microabcess', 'focal_hypergranulosis', 'disappearance_granular_layer',\n",
    "    'vacuolisation_damage', 'spongiosis', 'saw_tooth_appearance',\n",
    "    'follicular_horn_plug', 'perifollicular_parakeratosis', 'inflammatory_monoluclear_inflitrate',\n",
    "    'band_like_infiltrate', 'age', 'class'\n",
    "]\n",
    "\n",
    "# Load the data, treating '?' as missing values\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/dermatology/dermatology.data'\n",
    "df = pd.read_csv(url, names=cols, na_values='?')\n",
    "\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b874f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. INSPECT MISSING VALUES & CLASS DISTRIBUTION\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "print(\"\\nClass distribution (1-6, see UCI for disease types):\")\n",
    "print(df['class'].value_counts())\n",
    "\n",
    "# Bar chart of class balance\n",
    "df['class'].value_counts().sort_index().plot.bar(title=\"Class Distribution (1-6)\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7909dd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. AGE FEATURE DISTRIBUTIONS\n",
    "# Plot histograms for age feature since it has missing values\n",
    "plt.figure()\n",
    "df['age'].hist(bins=20)\n",
    "plt.title(f\"Histogram of age\")\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0263147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASS-WISE AGE HISTOGRAM\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "class_labels = sorted(df['class'].dropna().unique())\n",
    "for idx, cls in enumerate(class_labels, 1):\n",
    "    plt.subplot(2, 3, idx)\n",
    "    plt.hist(df[df['class'] == cls]['age'].dropna(), bins=15, color='skyblue', edgecolor='black')\n",
    "    plt.title(f'Class {cls}')\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Age Distribution by Class (non-empty values)', fontsize=16, y=1.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ebc872",
   "metadata": {},
   "source": [
    "The **age** feature, being a discrete numerical variable and typically regarded as a variable with a unimodal and approximately normal distribution, exhibits an unusually uneven distribution in its histogram. While the distribution peaks near the center, there are a considerable number of static values and outliers, particularly around the ages of *10*, *20*, *50*, and *60*. This phenomenon may be attributed to certain disease classes predominantly affecting specific age groups.\n",
    "\n",
    "To address missing values in the *age* feature, we use **class-wise mode imputation**. Since diseases often affect particular age groups, imputing missing ages with the most common (mode) value within each class helps generalize the typical age for that disease. This approach is further justified because human age, given a sufficiently large sample, tends to follow a natural (almost normal) distribution—making the mode a reasonable representative for each class's age group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc2de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. IMPUTE MISSING VALUES CLASS-WISE FOR 'age'\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "X_imputed = X.copy()\n",
    "\n",
    "# Impute 'age' by class-wise mode (most frequent value)\n",
    "for cls in y.unique():\n",
    "    mask = (y == cls)\n",
    "    age_mode = X.loc[mask, 'age'].mode().iloc[0]  # mode() returns a Series\n",
    "    X_imputed.loc[mask & X['age'].isna(), 'age'] = age_mode\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(\"\\nMissing after imputation:\")\n",
    "print(X_imputed.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4555e133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.5. ONE-HOT ENCODING FOR CATEGORICAL FEATURES\n",
    "# The dermatology dataset has categorical features (0-3 scale) that should be properly encoded\n",
    "# We'll exclude 'age' from one-hot encoding as it's a continuous numerical feature\n",
    "\n",
    "# Identify categorical columns (all except 'age')\n",
    "categorical_cols = [col for col in X_imputed.columns if col != 'age']\n",
    "continuous_cols = ['age']\n",
    "\n",
    "print(f\"Categorical features to encode: {len(categorical_cols)} features\")\n",
    "print(f\"Continuous features to keep: {continuous_cols}\")\n",
    "\n",
    "# Apply one-hot encoding to categorical features\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)  # drop='first' to avoid multicollinearity\n",
    "X_categorical_encoded = encoder.fit_transform(X_imputed[categorical_cols])\n",
    "\n",
    "# Create feature names for encoded columns\n",
    "encoded_feature_names = encoder.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Create DataFrame with encoded categorical features\n",
    "X_categorical_df = pd.DataFrame(X_categorical_encoded, columns=encoded_feature_names, index=X_imputed.index)\n",
    "\n",
    "# Combine continuous features with encoded categorical features\n",
    "X_final = pd.concat([X_imputed[continuous_cols], X_categorical_df], axis=1)\n",
    "\n",
    "print(f\"\\nOriginal feature count: {X_imputed.shape[1]}\")\n",
    "print(f\"Final feature count after one-hot encoding: {X_final.shape[1]}\")\n",
    "print(f\"Shape of final dataset: {X_final.shape}\")\n",
    "\n",
    "# Display first few columns to verify encoding\n",
    "print(f\"\\nFirst 5 columns of encoded dataset:\")\n",
    "print(X_final.iloc[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d521d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. CREATE 16 SUBSETS FOR ALL TRAIN/TEST RATIOS (EXPLICIT VARIABLE NAMES)\n",
    "\n",
    "# Shuffle the dataset first (using the one-hot encoded features)\n",
    "X_shuffled, y_shuffled = shuffle(X_final, y, random_state=42)\n",
    "\n",
    "# 40/60 split\n",
    "feature_train_40_60, feature_test_40_60, label_train_40_60, label_test_40_60 = train_test_split(\n",
    "    X_shuffled, y_shuffled, train_size=0.4, test_size=0.6, stratify=y_shuffled, random_state=42\n",
    ")\n",
    "# 60/40 split\n",
    "feature_train_60_40, feature_test_60_40, label_train_60_40, label_test_60_40 = train_test_split(\n",
    "    X_shuffled, y_shuffled, train_size=0.6, test_size=0.4, stratify=y_shuffled, random_state=42\n",
    ")\n",
    "# 80/20 split\n",
    "feature_train_80_20, feature_test_80_20, label_train_80_20, label_test_80_20 = train_test_split(\n",
    "    X_shuffled, y_shuffled, train_size=0.8, test_size=0.2, stratify=y_shuffled, random_state=42\n",
    ")\n",
    "# 90/10 split\n",
    "feature_train_90_10, feature_test_90_10, label_train_90_10, label_test_90_10 = train_test_split(\n",
    "    X_shuffled, y_shuffled, train_size=0.9, test_size=0.1, stratify=y_shuffled, random_state=42\n",
    ")\n",
    "\n",
    "# Print sample sizes and class balance for each split\n",
    "splits = [\n",
    "    (\"40/60\", feature_train_40_60, feature_test_40_60, label_train_40_60, label_test_40_60),\n",
    "    (\"60/40\", feature_train_60_40, feature_test_60_40, label_train_60_40, label_test_60_40),\n",
    "    (\"80/20\", feature_train_80_20, feature_test_80_20, label_train_80_20, label_test_80_20),\n",
    "    (\"90/10\", feature_train_90_10, feature_test_90_10, label_train_90_10, label_test_90_10),\n",
    "]\n",
    "for ratio, X_tr, X_te, y_tr, y_te in splits:\n",
    "    print(f\"\\nSplit {ratio}:\")\n",
    "    print(f\"  Train samples: {len(X_tr)}, Test samples: {len(X_te)}\")\n",
    "    print(f\"  Feature dimensions: {X_tr.shape[1]} features\")\n",
    "    print(\"  Train class balance:\")\n",
    "    print(y_tr.value_counts(normalize=True))\n",
    "    print(\"  Test class balance:\")\n",
    "    print(y_te.value_counts(normalize=True))\n",
    "\n",
    "# Now you have 16 variables: feature_train_40_60, label_train_40_60, feature_test_40_60, label_test_40_60, etc.\n",
    "# Each set corresponds to a different train/test split ratio, and all splits are stratified and shuffled.\n",
    "# All feature sets now include one-hot encoded categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6264723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. VISUALIZE CLASS DISTRIBUTIONS\n",
    "\n",
    "splits = [\n",
    "    (\"40/60\", label_train_40_60, label_test_40_60),\n",
    "    (\"60/40\", label_train_60_40, label_test_60_40),\n",
    "    (\"80/20\", label_train_80_20, label_test_80_20),\n",
    "    (\"90/10\", label_train_90_10, label_test_90_10),\n",
    "]\n",
    "\n",
    "# Print class counts and imbalance ratio before visualization\n",
    "print(\"Class counts per class:\")\n",
    "for cls, count in y.value_counts().sort_index().items():\n",
    "    print(f\"  Class {cls}: {count} samples\")\n",
    "imbalance_numerator = y.value_counts().max()\n",
    "imbalance_denominator = y.value_counts().min()\n",
    "imbalance_ratio = imbalance_numerator / imbalance_denominator\n",
    "print(f\"Class imbalance ratio (max/min): {imbalance_numerator}/{imbalance_denominator} = {imbalance_ratio:.2f}\")\n",
    "\n",
    "# Bar plot for class distribution (shows imbalance visually)\n",
    "plt.figure(figsize=(8, 5))\n",
    "y.value_counts().sort_index().plot(kind='bar', color='gray', alpha=0.7)\n",
    "plt.title(\"Class Distribution: Original Dataset\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pie chart for class proportions (optional, also shows imbalance)\n",
    "plt.figure(figsize=(6, 6))\n",
    "y.value_counts().sort_index().plot(kind='pie', autopct='%1.1f%%', startangle=90, colormap='tab20')\n",
    "plt.title(\"Class Proportion: Original Dataset\")\n",
    "plt.ylabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot train/test distributions for each split\n",
    "for ratio, y_train, y_test in splits:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    y_train.value_counts(normalize=True).sort_index().plot(kind='bar', alpha=0.7, label='Train', color='blue')\n",
    "    y_test.value_counts(normalize=True).sort_index().plot(kind='bar', alpha=0.7, label='Test', color='orange')\n",
    "    plt.title(f\"Class Distribution: Train/Test {ratio}\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Proportion\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a3dab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. CREATE & SAVE SPLIT SUMMARY REPORT\n",
    "\n",
    "import os\n",
    "\n",
    "output_dir = '../../results/additional_dataset'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "split_stats = []\n",
    "splits = [\n",
    "    (\"40/60\", label_train_40_60, label_test_40_60),\n",
    "    (\"60/40\", label_train_60_40, label_test_60_40),\n",
    "    (\"80/20\", label_train_80_20, label_test_80_20),\n",
    "    (\"90/10\", label_train_90_10, label_test_90_10),\n",
    "]\n",
    "\n",
    "class_labels = sorted(y.unique())  # [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "for ratio, y_train, y_test in splits:\n",
    "    row = {\n",
    "        'Split Ratio': ratio,\n",
    "        'Train Size': len(y_train),\n",
    "        'Test Size': len(y_test),\n",
    "    }\n",
    "    for cls in class_labels:\n",
    "        row[f'Train Class {cls}'] = (y_train == cls).sum()\n",
    "        row[f'Test Class {cls}'] = (y_test == cls).sum()\n",
    "    split_stats.append(row)\n",
    "\n",
    "summary_df = pd.DataFrame(split_stats)\n",
    "summary_path = os.path.join(output_dir, 'split_summary.csv')\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "print(f\"✅ Summary saved to {summary_path}\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\nSplit Summary:\")\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a418b703",
   "metadata": {},
   "source": [
    "**Next Steps:**  \n",
    "After running this data preparation script _(reaching here)_, please proceed to `03_additional_dataset_models_evaluation.ipynb` to create and evaluate classification models.  \n",
    "**Important:** These two notebooks are designed to be used within the same session to ensure all variables and data splits remain available for modeling and evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
