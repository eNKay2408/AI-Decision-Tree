{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34673b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template Notebook cho Data Preparation - Milestone 1\n",
    "# Th√†nh vi√™n: [T√äN] - Dataset: [T√äN DATASET]\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import utilities (sau khi ƒë√£ t·∫°o file)\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from visualization_utils import create_standard_plots, plot_class_distribution, plot_split_distributions\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD V√Ä KH√ÅM PH√Å D·ªÆ LI·ªÜU\n",
    "# ==========================================\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"1. LOAD V√Ä KH√ÅM PH√Å D·ªÆ LI·ªÜU\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# TODO: Load dataset c·ªßa b·∫°n\n",
    "# data = pd.read_csv('path/to/your/dataset.csv')\n",
    "\n",
    "# Hi·ªÉn th·ªã th√¥ng tin c∆° b·∫£n\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "print(\"\\nDataset info:\")\n",
    "print(data.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(data.head())\n",
    "\n",
    "# Ki·ªÉm tra missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Th·ªëng k√™ m√¥ t·∫£\n",
    "print(\"\\nDescriptive statistics:\")\n",
    "print(data.describe())\n",
    "\n",
    "# ==========================================\n",
    "# 2. DATA PREPROCESSING\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"2. DATA PREPROCESSING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# TODO: X·ª≠ l√Ω missing values n·∫øu c√≥\n",
    "# data = data.dropna()  # ho·∫∑c fillna()\n",
    "\n",
    "# TODO: X·ª≠ l√Ω categorical features (n·∫øu c√≥)\n",
    "# V√≠ d·ª• cho Palmer Penguins:\n",
    "# categorical_cols = ['sex', 'island']\n",
    "# data_encoded = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# TODO: Chu·∫©n b·ªã features v√† target\n",
    "# X = data.drop('target_column', axis=1)\n",
    "# y = data['target_column']\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "\n",
    "# ==========================================\n",
    "# 3. VISUALIZE CLASS DISTRIBUTION\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"3. VISUALIZE CLASS DISTRIBUTION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# S·ª≠ d·ª•ng function chu·∫©n\n",
    "dataset_name = \"[T√äN DATASET C·ª¶A B·∫°N]\"  # Thay ƒë·ªïi t√™n n√†y\n",
    "target_col = \"[T√äN C·ªòT TARGET]\"        # Thay ƒë·ªïi t√™n n√†y\n",
    "\n",
    "plot_class_distribution(data, target_col, f'{dataset_name} - Original Data',\n",
    "                       f'../visualizations/{dataset_name.lower().replace(\" \", \"_\")}/original_distribution.png')\n",
    "\n",
    "# ==========================================\n",
    "# 4. CHIA D·ªÆ LI·ªÜU THEO 4 T·ª∂ L·ªÜ\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"4. CHIA D·ªÆ LI·ªÜU THEO 4 T·ª∂ L·ªÜ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a c√°c t·ª∑ l·ªá split\n",
    "split_ratios = {\n",
    "    '40/60': 0.4,\n",
    "    '60/40': 0.6, \n",
    "    '80/20': 0.8,\n",
    "    '90/10': 0.9\n",
    "}\n",
    "\n",
    "# Dictionary ƒë·ªÉ l∆∞u c√°c split\n",
    "data_splits = {}\n",
    "target_splits = {}\n",
    "\n",
    "# Th·ª±c hi·ªán split cho t·ª´ng t·ª∑ l·ªá\n",
    "for ratio_name, train_size in split_ratios.items():\n",
    "    print(f\"\\nSplitting data with ratio {ratio_name}...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        train_size=train_size,\n",
    "        stratify=y,  # ƒê·∫£m b·∫£o stratified split\n",
    "        random_state=42,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # L∆∞u v√†o dictionary\n",
    "    data_splits[ratio_name] = (X_train, X_test)\n",
    "    target_splits[ratio_name] = (y_train, y_test)\n",
    "    \n",
    "    # In th√¥ng tin v·ªÅ split\n",
    "    print(f\"Train size: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "    print(f\"Test size: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "    print(f\"Train class distribution:\\n{y_train.value_counts()}\")\n",
    "    print(f\"Test class distribution:\\n{y_test.value_counts()}\")\n",
    "\n",
    "# ==========================================\n",
    "# 5. VISUALIZE SPLIT DISTRIBUTIONS  \n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"5. VISUALIZE SPLIT DISTRIBUTIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Chu·∫©n b·ªã data cho visualization\n",
    "splits_for_viz = {}\n",
    "for ratio_name in split_ratios.keys():\n",
    "    y_train, y_test = target_splits[ratio_name]\n",
    "    splits_for_viz[ratio_name] = (y_train, y_test)\n",
    "\n",
    "# V·∫Ω bi·ªÉu ƒë·ªì so s√°nh\n",
    "plot_split_distributions(splits_for_viz, dataset_name, \n",
    "                        f'../visualizations/{dataset_name.lower().replace(\" \", \"_\")}/split_distributions.png')\n",
    "\n",
    "# ==========================================\n",
    "# 6. L∆ØU K·∫æT QU·∫¢\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"6. L∆ØU K·∫æT QU·∫¢\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c output\n",
    "import os\n",
    "output_dir = f'../results/{dataset_name.lower().replace(\" \", \"_\")}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# L∆∞u c√°c split ƒë·ªÉ s·ª≠ d·ª•ng trong Milestone 2\n",
    "import pickle\n",
    "\n",
    "# L∆∞u data splits\n",
    "with open(f'{output_dir}/data_splits.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'data_splits': data_splits,\n",
    "        'target_splits': target_splits,\n",
    "        'original_data': (X, y),\n",
    "        'dataset_info': {\n",
    "            'name': dataset_name,\n",
    "            'shape': data.shape,\n",
    "            'features': list(X.columns),\n",
    "            'target': target_col,\n",
    "            'classes': list(y.unique())\n",
    "        }\n",
    "    }, f)\n",
    "\n",
    "print(f\"‚úÖ Data splits saved to {output_dir}/data_splits.pkl\")\n",
    "\n",
    "# T·∫°o summary report\n",
    "summary_stats = []\n",
    "for ratio_name in split_ratios.keys():\n",
    "    y_train, y_test = target_splits[ratio_name]\n",
    "    summary_stats.append({\n",
    "        'Split Ratio': ratio_name,\n",
    "        'Train Size': len(y_train),\n",
    "        'Test Size': len(y_test),\n",
    "        'Train Class 0': (y_train == 0).sum() if 0 in y_train.values else 'N/A',\n",
    "        'Train Class 1': (y_train == 1).sum() if 1 in y_train.values else 'N/A',\n",
    "        'Test Class 0': (y_test == 0).sum() if 0 in y_test.values else 'N/A', \n",
    "        'Test Class 1': (y_test == 1).sum() if 1 in y_test.values else 'N/A'\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "summary_df.to_csv(f'{output_dir}/split_summary.csv', index=False)\n",
    "print(f\"‚úÖ Summary saved to {output_dir}/split_summary.csv\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\nSplit Summary:\")\n",
    "print(summary_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MILESTONE 1 COMPLETED ‚úÖ\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Dataset: {dataset_name}\")\n",
    "print(f\"Original samples: {len(data)}\")\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"Classes: {len(y.unique())}\")\n",
    "print(f\"Splits created: {len(split_ratios)}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# ==========================================\n",
    "# 7. CHECKLIST CHO COORDINATOR\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\nüìã CHECKLIST CHO COORDINATOR:\")\n",
    "print(\"‚ñ° Dataset ƒë∆∞·ª£c load th√†nh c√¥ng\")\n",
    "print(\"‚ñ° Missing values ƒë∆∞·ª£c x·ª≠ l√Ω\")\n",
    "print(\"‚ñ° Categorical features ƒë∆∞·ª£c encode (n·∫øu c√≥)\")\n",
    "print(\"‚ñ° 4 t·ª∑ l·ªá split ƒë∆∞·ª£c t·∫°o v·ªõi stratified sampling\")\n",
    "print(\"‚ñ° Class distributions ƒë∆∞·ª£c visualize\")\n",
    "print(\"‚ñ° K·∫øt qu·∫£ ƒë∆∞·ª£c l∆∞u v√†o ƒë√∫ng th∆∞ m·ª•c\")\n",
    "print(\"‚ñ° Summary statistics ƒë∆∞·ª£c t·∫°o\")\n",
    "print(\"\\nüîÑ G·ª≠i k·∫øt qu·∫£ n√†y cho Coordinator ƒë·ªÉ review!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
